{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction :\n",
    "\n",
    "Fits files are a common format for storing astronomical data. They are used by many telescopes and observatories. The format is very flexible and can be used to store many different types of data. \n",
    "We have a dataset of fits images from a telescope with a timer, our aim from this notebook is to do Digits Recognition on the timer using CNN.\n",
    "\n",
    "## Datasets :\n",
    "\n",
    "For training our 1st model we will use the famous [MNIST](http://yann.lecun.com/exdb/mnist/) dataset as first try then we will use a labeled dataset of the timer images.\n",
    "\n",
    "For the 2nd model we will use the same dataset of the telescope camera images, this data itself is from a private source so we can't share it, only a segment of it is shared in this notebook.\n",
    "\n",
    "## Content :\n",
    "\n",
    "1. [Importing Libraries](#1)\n",
    "2. [Loading and Preprocessing Data](#2)\n",
    "3. [MNIST Model](#3)\n",
    "4. [Custom Model](#4)\n",
    "5. [Conclusion](#5)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-Importing Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# fits manipulation \n",
    "from astropy.io import fits\n",
    "from astropy.visualization import simple_norm\n",
    "\n",
    "# image processing\n",
    "from PIL import Image\n",
    "from PIL import ImageEnhance\n",
    "from PIL import ImageFilter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Modeling\n",
    "import torch\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Loading and Preprocessing Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - Processing the Timer Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Define the path to your FITS file\n",
    "fits_file_path = 'fits_file/selected_images.fits'\n",
    "\n",
    "# Open the FITS file\n",
    "hdulist = fits.open(fits_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fits file is made of ```HDUs (Header Data Units)```, each HDU can contain a table or an image, our case only contains images, each HDU has a header and a data part, the header contains information about the image like the date, the telescope used, the exposure time, etc. The data part contains the image itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "hdus = [hdulist[i].data for i in range(len(hdulist))]\n",
    "\n",
    "\n",
    "plt.imshow(hdus[0], cmap='gray', norm=simple_norm(hdus[0], 'sqrt', percent=99.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Our aim now is to extract the time from the images, 1st step is to crop the image just to include the timer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "for i in hdus[0:3]:\n",
    "    roi = i[-80:-10, 30:270]\n",
    "    plt.imshow(roi, cmap='gray', norm=simple_norm(i, 'sqrt', percent=99.5))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The letters look a bit overlapped, let's create a function to separate them**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def replace_columns_with_zeros(img):\n",
    "    # Get the pixel data as a NumPy array\n",
    "    img_data = np.array(img)\n",
    "\n",
    "    # Replace the specwwified columns with zeros\n",
    "    # Start from the highest index\n",
    "    indices = [225,206,197,187,172,160,149,142,132,120,114,103,86,75,64,55,46,37,27,18]\n",
    "    for index in indices :\n",
    "        if index == 172 or index == 86:\n",
    "            for _ in range(15):\n",
    "                img_data[:,index] = 0\n",
    "                img_data = np.insert(img_data, index, 0, axis=1)\n",
    "        else:\n",
    "            for _ in range(7):\n",
    "                img_data[:,index] = 0\n",
    "                img_data = np.insert(img_data, index, 0, axis=1)\n",
    "\n",
    "\n",
    "    # Convert the NumPy array back to an image\n",
    "    img = Image.fromarray(img_data)\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "# now let's test the function\n",
    "\n",
    "roi = hdus[0][-80:-10, 30:270]\n",
    "plt.imshow(roi, cmap='gray', norm=simple_norm(i, 'sqrt', percent=99.5))\n",
    "plt.imsave('roi.png', roi, cmap='gray')\n",
    "plt.title('Original')\n",
    "plt.show()\n",
    "roi = replace_columns_with_zeros(roi)\n",
    "plt.imshow(roi, cmap='gray', norm=simple_norm(i, 'sqrt', percent=99.5))\n",
    "plt.title('With Gaps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're gonna create a function that does general preprocessing on the images, it will do the following :\n",
    "\n",
    "1. Inhance the contrast of the image : for our case the time is the white part of the image, so we will make it more white and the background more black.\n",
    "\n",
    "2. Convert the image to grayscale : so we can use some methods that only work on grayscale images.\n",
    "\n",
    "3. ```Thresholding``` : which means reducing the possible intensity values to 2 values, 0 and 255. that's done by setting a threshold value, all the pixels with intensity values less than the threshold are set to 0 and all the pixels with intensity values greater than the threshold are set to 255.\n",
    "\n",
    "4. ```Deblurring``` : the images are a bit blurry, so we will use a deblurring filter to make them clearer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def process_image(img):\n",
    "\n",
    "\n",
    "        # Convert the ROI to a PIL Image (for easy handling)\n",
    "        roi_image = Image.fromarray(img)\n",
    "\n",
    "        # Set the DPI (dots per inch) for the PIL image\n",
    "        roi_image.info['dpi'] = (500, 500)  # Set your desired DPI here\n",
    "        \n",
    "        #call the replace_columns function\n",
    "        roi_image = replace_columns_with_zeros(roi_image)\n",
    "\n",
    "        # Enhance the image\n",
    "        enhancer = ImageEnhance.Contrast(roi_image)\n",
    "        roi_image = enhancer.enhance(2)\n",
    "\n",
    "        # Convert the image ti grayscale\n",
    "        roi_image = roi_image.convert('L')\n",
    "        \n",
    "        # Apply direct thresholding\n",
    "        threshold_value = 75\n",
    "        roi_image = roi_image.point(lambda x: 0 if x < threshold_value else x)\n",
    "        \n",
    "      \n",
    "        roi_image = roi_image.filter(ImageFilter.UnsharpMask(radius=2, percent=150, threshold=1))\n",
    "        \n",
    "        return roi_image\n",
    "        \n",
    "# Now let's test the function\n",
    "roi = hdus[0][-80:-10, 30:270]\n",
    "process_image(roi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with the normalization the background with all those stars is still a problem, let's try to remove it. to do so let's write a function ```custom_process``` to deal with the major issues in the images.\n",
    "\n",
    "Another custom method we will do is removing the noise that's resulted from thebetween-digits gaps we created, we can see some small groups of white pixels that doesn't belong to any digit, we will remove them by algorithm thath cheks the size of the white groups and remove the ones that are smaller than a certain threshold.\n",
    "\n",
    "\n",
    "**Here's how would the process function look like :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def custom_process(image):\n",
    "    \n",
    "    \n",
    "    # Convert the image to a NumPy array\n",
    "    image_data = np.array(image)\n",
    "    \n",
    "    # Create a copy of the image data to modify\n",
    "    modified_data = np.copy(image_data)\n",
    "\n",
    "    # Define the threshold value\n",
    "    threshold_value = 55\n",
    "\n",
    "    # Define the size of the surrounding matrix\n",
    "    matrix_size = (4, 3)\n",
    "\n",
    "    # Define the size of the surrounding matrix for the 3x3 matrix\n",
    "    matrix_size_3x3 = 3\n",
    "\n",
    "    # Define the minimum number of pixels in the surrounding matrix that must be above the threshold value\n",
    "    min_pixels_above_threshold = 8\n",
    "\n",
    "    # Iterate over each pixel in the image\n",
    "    for i in range(matrix_size[0], image_data.shape[0] - matrix_size[0]):\n",
    "        for j in range(matrix_size[1], image_data.shape[1] - matrix_size[1]):\n",
    "            \n",
    "            if image_data[i, j] > threshold_value and image_data[i, j] < 100:\n",
    "                \n",
    "                surrounding_matrix = image_data[i - matrix_size[0]:i + matrix_size[0] + 1, j - matrix_size[1]:j + matrix_size[1] + 1]\n",
    "                surrounding_matrix_3x3 = image_data[i - matrix_size_3x3:i + matrix_size_3x3 + 1, j - matrix_size_3x3:j + matrix_size_3x3 + 1]\n",
    "\n",
    "                # Check if at least min_pixels_above_threshold pixels in the surrounding matrix are above the threshold value\n",
    "                if np.sum(surrounding_matrix > image_data[i, j] + 55) < min_pixels_above_threshold:\n",
    "\n",
    "                    modified_data[i - matrix_size[0]:i + matrix_size[0] + 1, j - matrix_size[1]:j + matrix_size[1] + 1] = 0\n",
    "                    modified_data[i - matrix_size_3x3:i + matrix_size_3x3 + 1, j - matrix_size_3x3:j + matrix_size_3x3 + 1] = 0\n",
    "\n",
    "    \n",
    "    modified_image = Image.fromarray(modified_data)\n",
    "\n",
    "    return modified_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can now create a loop that extracts the images from the ````fits``` file and apply the processing functions on them, let's view the results :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "for i, hdu in enumerate(hdulist[:3]):\n",
    "    if hdu.data is not None:\n",
    "        \n",
    "        # Extract the image data as a NumPy array\n",
    "        image_data = hdu.data\n",
    "\n",
    "        # Crop the image to the defined ROI (bottom left)\n",
    "        roi = image_data[-80:-10, 30:270]\n",
    "        \n",
    "        #the algorithm\n",
    "        roi_image = process_image(roi)\n",
    "\n",
    "        \n",
    "        plt.imshow(roi_image,cmap='gray')\n",
    "        plt.show()\n",
    "        \n",
    "        # Custom processing\n",
    "        roi_image = custom_process(roi_image)\n",
    "        \n",
    "        # Save the image\n",
    "        roi_image.save('roi_{}.png'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Labeling the Timer Images\n",
    "\n",
    "The original fits file is too large, and we used this part of it cause it contains in the metadata the time the image was taken, so we can use it as a label for our images, let's extract the time from the metadata and add it to the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "# digit extractor function\n",
    "\n",
    "def extract_digits(hdu,image,j,labels):\n",
    "\n",
    "    pattern = hdu.header['DATE']\n",
    "    \n",
    "    # create a list that only contains the figits in pattern\n",
    "    digits = [int(char) for char in pattern[-8:] if char.isdigit()]\n",
    "    # indices of the last 3 digits in the image\n",
    "    indices = [[320,336],[337,353],[352,368]]\n",
    "\n",
    "\n",
    "    for i,index in enumerate(indices):\n",
    "        # Crop the image\n",
    "        digit_image = image.crop((index[0], 18, index[1], 54))\n",
    "\n",
    "        # convert the image to a NumPy array\n",
    "        digit_image = np.array(digit_image)\n",
    "            \n",
    "        # add 6 dark columns to the left and right of the image \n",
    "        digit_image = np.pad(digit_image, ((0, 0), (6, 6)), 'constant', constant_values=(0, 0))\n",
    "        \n",
    "        \n",
    "        # save the image to a folder called 'digits data'\n",
    "        #plt.imsave('digits_data/{}/{}.png'.format(digits[i],len(labels[digits[i]])+i), digit_image, cmap='gray')\n",
    "        \n",
    "        # save it's label to a list called \n",
    "        labels[digits[i]].append(len(labels[digits[i]])+i)\n",
    "        \n",
    "    return labels    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "all_labels = {0:[],1:[],2:[],3:[],4:[],5:[],6:[],7:[],8:[],9:[]}\n",
    "for j, hdu in enumerate(hdulist[::2]):   #we only take pair HDUs for a reason described down in \"Important Note\"\n",
    "    roi = hdu.data[-80:-10, 30:270]\n",
    "    roi_image = process_image(roi)\n",
    "    roi_image = custom_process(roi_image)\n",
    "    all_labels = extract_digits(hdu, roi_image, j, all_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing the number of digits in each class\n",
    "for i in range(10):\n",
    "    print('Number of {}s: {}'.format(i, len(all_labels[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now evrything is set for the fits extraction and preprocessing, now we will move to the MNIST dataset and create our model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important  Note :\n",
    "We took the pair HDUs cause the physicians who gave us the data used a software that fills up the time in the metadata by adding the time of the previous image to the exposure time, but this method isn't accurate cause there's no stable time between the images, so some of the DATE in the headers we used are wrongs and we had to clean them after storing them in each class folder.\n",
    "\n",
    "The good thing that the folder resulted ```new_folder``` contains the images with tehir correct labels, so we can use it directly without the need to extract the time from the metadata, but if you want to use the original fits file you can use the code below to extract the time from the metadata and add it to the images then clean it like we did."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. MNIST Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A - Buidling the Model\n",
    "\n",
    "The MNIST dataset is a dataset of handwritten digits, it contains 60000 images for training and 10000 images for testing, each image is 28x28 pixels, we will use it to train our model then we will use the timer images to test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "# Defineing the CNN model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(7*7*64, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(-1, 7*7*64)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B - Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training process\n",
    "def train(model, train_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "def evaluate(model, test_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "train_dataset = MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = MNIST(root='./data', train=False, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "\n",
    "model = CNNModel().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "num_epochs = 1  # changing it won't make a difference\n",
    "#for epoch in range(num_epochs):                              # uncoment this for simpler output\n",
    " #   train(model, train_loader, optimizer, criterion, device)\n",
    "  #  accuracy = evaluate(model, test_loader, device)\n",
    "   # print(f\"Epoch {epoch+1}/{num_epochs}, Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation \n",
    "\n",
    "train_accuracy_list = []\n",
    "test_accuracy_list = []\n",
    "\n",
    "\n",
    "num_epochs = 3  # you can change it just to see the differences in the plot \n",
    "for epoch in range(num_epochs):\n",
    "    train(model, train_loader, optimizer, criterion, device)\n",
    "    train_accuracy = evaluate(model, train_loader, device)\n",
    "    test_accuracy = evaluate(model, test_loader, device)\n",
    "    train_accuracy_list.append(train_accuracy)\n",
    "    test_accuracy_list.append(test_accuracy)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Accuracy: {train_accuracy:.2f}%, Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "\n",
    "epochs = range(1, num_epochs+1)\n",
    "plt.plot(epochs, train_accuracy_list, label='Train Accuracy')\n",
    "plt.plot(epochs, test_accuracy_list, label='Test Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "k=0\n",
    "for i, hdu in enumerate(hdulist):\n",
    "    if hdu.data is not None:\n",
    "        if k>3:\n",
    "            break\n",
    "        k+=1\n",
    "        \n",
    "        \n",
    "\n",
    "        image_data = hdu.data\n",
    "        roi = image_data[-80:-10, 30:270]\n",
    "        roi_image = process_image(roi)\n",
    "    \n",
    "        plt.imshow(roi_image, cmap='gray')\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "        roi_image = custom_process(roi_image)\n",
    "        \n",
    "        # the list of start-end indices for each digit\n",
    "        indices = [[6, 22], [22, 36], [55, 71], [71, 87], [104, 120], [121, 137], [154, 170], [171, 187], [203, 219], [223,239],[254,270],[270,286],[303,319],[320,336],[337,353],[352,368],[380,396]]\n",
    "\n",
    "        for index in indices:\n",
    "            digit_image = roi_image.crop((index[0], 18, index[1], 54))\n",
    "            plt.imshow(digit_image, cmap='gray')\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "            digit_image = np.array(digit_image)\n",
    "            digit_image = np.pad(digit_image, ((0, 0), (6, 6)), 'constant', constant_values=(0, 0))\n",
    "\n",
    "            digit_image = Image.fromarray(digit_image) \n",
    "            digit_image = digit_image.resize((28, 28))\n",
    "            \n",
    "\n",
    "            threshold_value = 100\n",
    "            digit_image = digit_image.point(lambda x: 0 if x < threshold_value else x)\n",
    "            digit_image = np.array(digit_image)\n",
    "            \n",
    "\n",
    "            digit_image = torch.from_numpy(digit_image)\n",
    "            digit_image = digit_image.unsqueeze(0)\n",
    "            digit_image = digit_image.float()\n",
    "            \n",
    "\n",
    "            digit_image /= 255.0\n",
    "            digit = torch.argmax(model(digit_image.to(device))).item()\n",
    "        \n",
    "            print(digit, end=' ')\n",
    "            \n",
    "            break # remove this line to predict all digits\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We see that this model doesn't perform well on the timer images, this may be due to the diffrence between the nature of the 2 datasets.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model based on Timer Images\n",
    "\n",
    "Now we will use the timer images to train our model, we will use the same architecture as the MNIST model, but we will change the input shape to fit the timer images.\n",
    "\n",
    "for this model we will create a custom dataset class that will load the images and labels from the folders we created in the preprocessing part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A - Datastes and Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "# Define the transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "\n",
    "root_dir = \"new_folder\"\n",
    "\n",
    "# Load the train and test datasets using ImageFolder\n",
    "train_dataset = ImageFolder(root=os.path.join(root_dir, \"train\"), transform=transform)\n",
    "test_dataset = ImageFolder(root=os.path.join(root_dir, \"test\"), transform=transform)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B - Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5)\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 256)  # Adjusted the size\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C - Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Net().to(device)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)  # Adjusted the learning rate\n",
    "\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "                \n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "                \n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:\n",
    "            print(f\"[Epoch {epoch+1}, Batch {i+1}] Loss: {running_loss / 2000:.3f}\")\n",
    "            running_loss = 0.0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D - Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing loop\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "correct = 0  \n",
    "total = 0  \n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        y_pred.extend(predicted.tolist())\n",
    "        y_true.extend(labels.tolist())\n",
    "        total += labels.size(0)  \n",
    "        correct += (predicted == labels).sum().item()  \n",
    "\n",
    "accuracy = (100 * correct / total)\n",
    "classification = classification_report(y_true, y_pred)\n",
    "confusion = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Accuracy on test set: {accuracy:.2f}%\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PEEEEEEEEEEERFECT, now we have a model that can recognize the digits in the timer images, let's complete adding the Dates to the impair hdus.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "k = 0\n",
    "for i, hdu in enumerate(hdulist[1::2]):  #here' we're gonna fill the imapir HDUs cause the pair ones are aleady filled like we said in the note\n",
    "    if hdu.data is not None:\n",
    "        \n",
    "        if k>10:   #remove this line to predict all digits\n",
    "            break   \n",
    "        k=k+1\n",
    "        \n",
    "        plt.imshow(hdu.data, cmap='gray')\n",
    "        plt.show()\n",
    "\n",
    "        image_data = hdu.data\n",
    "\n",
    "        roi = image_data[-80:-10, 30:270]\n",
    "        roi_image = process_image(roi)\n",
    "        roi_image = custom_process(roi_image)\n",
    "        \n",
    "        # the list of start-end indices for each digit\n",
    "        indices = [[6, 22], [22, 36], [55, 71], [71, 87], [104, 120], [121, 137], [154, 170], [171, 187], [203, 219], [223,239],[254,270],[270,286],[303,319],[320,336],[337,353],[352,368],[380,396]]\n",
    "        \n",
    "        date = \"\"\n",
    "        \n",
    "        # Loop through the indices and predict the digit for each sub-image\n",
    "        for index in indices:\n",
    "\n",
    "            digit_image = roi_image.crop((index[0], 18, index[1], 54))\n",
    "            digit_image = np.array(digit_image)\n",
    "            digit_image = np.repeat(digit_image[:, :, np.newaxis], 3, axis=2)\n",
    "            digit_image = np.pad(digit_image, ((0, 0), (6, 6), (0, 0)), 'constant', constant_values=(0, 0))\n",
    "            digit_image = Image.fromarray(digit_image) \n",
    "            digit_image = digit_image.resize((28, 28))\n",
    "            \n",
    "            digit_image = transforms.ToTensor()(digit_image)\n",
    "            digit_image = digit_image.unsqueeze(0)\n",
    "        \n",
    "            digit_image = transforms.Normalize((0.5,), (0.5,))(digit_image)\n",
    "            digit = torch.argmax(model(digit_image.to(device))).item()\n",
    "            \n",
    "\n",
    "            date += str(digit)\n",
    "        \n",
    "        # Setting the DATE header with the concatenated sub-images\n",
    "        hdu.header['DATE'] = date\n",
    "        print(date)\n",
    "        print(hdu.header['DATE'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model looks doing well, some mistakes he does are due to the output function argmax that somtimes he gives +-1 the correct digit, with more epochs and better coroping it will be better. also the most important digits to recognize are the  meliseconds, and the model is doing well on them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Conclusion\n",
    "\n",
    "**We have created 2 models that can recognize the digits in the timer images, the 1st one is trained on the MNIST dataset and the 2nd one is trained on the timer images themselves.**\n",
    "\n",
    "**The 2nd model is better than the 1st one, but it's still not perfect, we can add validation data to confirm it's performace, if it kept doing great it would be a great start of trying to optimize it for fun and learning.**\n",
    "\n",
    "**Thank you for reading this notebook, I hope you liked it, if you have any questions or suggestions please leave them in the comments.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
